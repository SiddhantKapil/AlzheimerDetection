{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-1\n",
    "###  Lode modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib # to read nii files\n",
    "import shutil # for file operations\n",
    "import glob  # use to make file list from diectory\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "import cv2 # opencv library\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score\n",
    "from skimage import filters\n",
    "from skimage import measure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.morphology import closing, square\n",
    "import traceback\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Alzheimer',\"MCI\", 'Normal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-2\n",
    "### Converting Nii files into numpy 3-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on Alzheimer...\n",
      "working on A104_130 (copy).nii...\n",
      "working on A104_130 (8th copy).nii...\n",
      "working on A104_130 (7th copy).nii...\n",
      "working on A104_130 (3rd copy).nii...\n",
      "working on A104_130.nii...\n",
      "working on A104_130 (6th copy).nii...\n",
      "working on A104_130 (9th copy).nii...\n",
      "working on A104_130 (4th copy).nii...\n",
      "working on A104_130 (5th copy).nii...\n",
      "working on A104_130 (another copy).nii...\n",
      "working on MCI...\n",
      "working on A104_130 (copy).nii...\n",
      "working on A104_130 (8th copy).nii...\n",
      "working on A104_130 (7th copy).nii...\n",
      "working on A104_130 (3rd copy).nii...\n",
      "working on A104_130.nii...\n",
      "working on A104_130 (6th copy).nii...\n",
      "working on A104_130 (9th copy).nii...\n",
      "working on A104_130 (4th copy).nii...\n",
      "working on A104_130 (5th copy).nii...\n",
      "working on A104_130 (another copy).nii...\n",
      "working on Normal...\n",
      "working on A104_130 (copy).nii...\n",
      "working on A104_130 (8th copy).nii...\n",
      "working on A104_130 (7th copy).nii...\n",
      "working on A104_130 (3rd copy).nii...\n",
      "working on A104_130.nii...\n",
      "working on A104_130 (6th copy).nii...\n",
      "working on A104_130 (9th copy).nii...\n",
      "working on A104_130 (10th copy).nii...\n",
      "working on A104_130 (4th copy).nii...\n",
      "working on A104_130 (5th copy).nii...\n",
      "working on A104_130 (another copy).nii...\n",
      "('3d array shape : ', (45, 54, 140))\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "# Declaring the home variables that will be used throughout the script.\n",
    "\n",
    "home_files_dir = '/home/charu/Alzheimer Detection/code/data/'\n",
    "#output_dir='/home/ubuntu/final_src/DeepNeuralnets--Alzheimer/videoclassification/'\n",
    "\n",
    "#removing existing \"output_array\" (old data) folder from the directory '/home/ubuntu/Select_original_fmri/images'\n",
    "try:\n",
    "    os.mkdir('output_array')\n",
    "except:\n",
    "    shutil.rmtree('output_array')\n",
    "    os.mkdir('output_array')\n",
    "# iterating /home/ubuntu/Select_original_fmri/niifiles/class_ (Alzheimer, MCI , Normal)\n",
    "for class_ in classes:\n",
    "    print ('working on ' + class_ + '...')\n",
    "    \n",
    "    for root, dir ,files in os.walk(os.path.join(home_files_dir, class_)): \n",
    "        \n",
    "        # making class folder inside the '/home/ubuntu/Select_original_fmri/images' directory\n",
    "        try:\n",
    "            #print('test1')\n",
    "            os.mkdir( 'output_array' +'/'+ class_ + '/')\n",
    "            \n",
    "        except:\n",
    "            #print('caught!!!')\n",
    "            pass\n",
    "        # iterating through each nii file in each class in the '/home/ubuntu/Select_original_fmri/niifiles' directory\n",
    "        count = 0\n",
    "        for file_ in files:\n",
    "            print 'working on ' + file_ + '...'\n",
    "            try:\n",
    "                # extracting data from nii files\n",
    "                x = nib.load(os.path.join(home_files_dir , class_) + '/' + file_).get_data()\n",
    "                #print(\"x_shape\",x.shape)\n",
    "                x_arr=np.array(x)\n",
    "                #print (\"x_arr shape : \",x_arr.shape)\n",
    "                #converting X_arr into 3_D array.........\n",
    "                x_3d=x_arr.reshape(x_arr.shape[0],x_arr.shape[1],x_arr.shape[2]*x_arr.shape[3])\n",
    "                np.save('output_array' +'/'+ class_ + '/'+str(file_)+str(count),x_3d)   \n",
    "                count+=1\n",
    "                #print(\"3d array shape : \",x_3d.shape)\n",
    "\n",
    "            except:\n",
    "                print(\"in last excpet block\")\n",
    "                print file_\n",
    "print(\"3d array shape : \",x_3d.shape)\n",
    "print('done..')\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-3\n",
    "### Prepare Data for training\n",
    "#### Dividing data into test and training sets and making output labels for corresponding classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on Alzheimer...\n",
      "('root: ', 'output_array/Alzheimer')\n",
      "working on MCI...\n",
      "('root: ', 'output_array/MCI')\n",
      "working on Normal...\n",
      "('root: ', 'output_array/Normal')\n",
      "('X train shape: ', (22, 45, 54, 140))\n",
      "('Y label shape: ', (22,))\n",
      "('X test shape: ', (9, 45, 54, 140))\n",
      "('Y test label: ', (9,))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_list=[]\n",
    "test_list=[]\n",
    "file_list=[]\n",
    "\n",
    "for class_ in classes:\n",
    "    print ('working on ' + class_ + '...')\n",
    "    \n",
    "    for root, dir ,files in os.walk(os.path.join('output_array', class_)): \n",
    "        length=len(files)\n",
    "        print(\"root: \",root)\n",
    "        if class_ == 'Alzheimer': \n",
    "            for file_ in files:            \n",
    "                \n",
    "                file_list.append((np.load(root+'/'+file_),0))\n",
    "            #image data division\n",
    "            test_list=file_list[:int(length*0.3)]\n",
    "            train_list=file_list[len(test_list):]\n",
    "                 \n",
    "                \n",
    "        elif class_ == 'MCI':\n",
    "            len2=len(file_list)\n",
    "            for file_ in files:            \n",
    "                \n",
    "                file_list.append((np.load(root+'/'+file_),1))\n",
    "            #image  data  diision\n",
    "            test_list +=file_list[len2:int(len2+length*0.3)]\n",
    "            train_list += file_list[int(len2+length*0.3):]\n",
    "           \n",
    "            \n",
    "        # for Normal Class\n",
    "        \n",
    "        else:\n",
    "            len3=len(file_list)\n",
    "            for file_ in files:            \n",
    "        \n",
    "                file_list.append((np.load(root+'/'+file_),2))\n",
    "            #image  data  diision\n",
    "            test_list += file_list[len3:int(len3+length*0.3)]\n",
    "            train_list += file_list[int(len3+length*0.3):]\n",
    "            \n",
    "#print (\"length of train list: \",len(train_list))\n",
    "#print(\"length of train labels:\",len(train_labels))\n",
    "#print(\"length of test list:\",len(test_list))\n",
    "#print(\"length of test labels:\",len(test_labels))\n",
    "np.random.shuffle(train_list)\n",
    "np.random.shuffle(test_list)\n",
    "X_train,Y_train=zip(*train_list)\n",
    "X_test,Y_test=zip(*test_list)\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n",
    "\n",
    "print(\"X train shape: \",X_train.shape)\n",
    "print(\"Y label shape: \",Y_train.shape)\n",
    "print(\"X test shape: \",X_test.shape)\n",
    "print(\"Y test label: \",Y_test.shape)\n",
    "       \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-4\n",
    "## Train \n",
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "#from keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-4\n",
    "### set requied parameters for model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 45, 54, 140)\n",
      "(22, 3)\n",
      "(9, 45, 54, 140)\n",
      "(9, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "input_shape = [None,None,140]\n",
    "Y_train= np_utils.to_categorical(Y_train, num_classes=3)\n",
    "Y_test= np_utils.to_categorical(Y_test, num_classes=3)\n",
    "#np.random.shuffle(data)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step-5\n",
    "### Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, None, None, 32)    40352     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 64)    18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 461,155\n",
      "Trainable params: 461,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-6\n",
    "### Complie Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-7\n",
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22 samples, validate on 9 samples\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 4s 190ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 4s 190ms/step - loss: 10.2570 - acc: 0.3636 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 4s 191ms/step - loss: 10.2570 - acc: 0.3636 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 4s 200ms/step - loss: 10.5219 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 5s 226ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 6s 261ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 5s 231ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 6s 253ms/step - loss: 10.2570 - acc: 0.3636 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 6s 257ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 6s 253ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 5s 243ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 5s 249ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 5s 238ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 5s 225ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 5s 224ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 6s 263ms/step - loss: 10.2570 - acc: 0.3636 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 6s 252ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 5s 228ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 5s 224ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 5s 226ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 5s 227ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 5s 242ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 5s 241ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 5s 225ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 5s 226ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 5s 216ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 5s 219ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 5s 219ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 5s 222ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 5s 223ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 5s 238ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 5s 223ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 10.2570 - acc: 0.3636 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 5s 221ms/step - loss: 11.7223 - acc: 0.2727 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 5s 228ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 6s 256ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 6s 265ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 5s 246ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 5s 246ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 5s 244ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 5s 243ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 5s 243ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "22/22 [==============================] - 4s 199ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 4s 190ms/step - loss: 11.5148 - acc: 0.2727 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 4s 189ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 4s 190ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 4s 193ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 4s 193ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 4s 195ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 4s 198ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 4s 195ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 4s 195ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 4s 195ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 4s 194ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 4s 200ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 4s 197ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 5s 248ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 5s 246ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 5s 246ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 5s 250ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 5s 241ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 5s 246ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 5s 241ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 6s 257ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 5s 242ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 5s 242ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 5s 242ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 5s 244ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 5s 244ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 5s 241ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 5s 248ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 5s 244ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 10.9896 - acc: 0.3182 - val_loss: 10.7454 - val_acc: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7aa9b2fe90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-8\n",
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 10.745396614074707)\n",
      "('Test accuracy:', 0.3333333432674408)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (2, 3), (4, 5)]\n"
     ]
    }
   ],
   "source": [
    "lst=[(1,2),(2,3),(4,5)]\n",
    "#lst=np.array(lst)\n",
    "print(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 4, 'as')\n",
      "(2, 3, 5, 0)\n"
     ]
    }
   ],
   "source": [
    "x,y= zip(*lst)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (2, 3), (4, 5), ('as', 0)]\n"
     ]
    }
   ],
   "source": [
    "lst.append((\"as\",0))\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 'as'), (4, 4), (5, 5), (6, 6), (7, 'y'), (7, 'p')]\n",
      "(12, 4, 5, 6, 7, 7)\n",
      "('as', 4, 5, 6, 'y', 'p')\n"
     ]
    }
   ],
   "source": [
    "x=[12,4,5,6,7,7]\n",
    "y=['as',4,5,6,'y','p']\n",
    "lst=zip(x,y)\n",
    "print(lst)\n",
    "x1,y1=zip(*lst)\n",
    "print x1\n",
    "print y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
